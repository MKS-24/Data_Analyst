{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### `**# #                                                              # PANDAS**`"
      ],
      "metadata": {
        "id": "ngGKS82MbybV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function\n"
      ],
      "metadata": {
        "id": "qXccG75OcAld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "df = sns.load_dataset('titanic')\n",
        "print(df)\n",
        "# head by default 5 first rows of data deta    head(n) or head()\n",
        "print(df.head(7))\n",
        "print()\n",
        "\n",
        "\n",
        "\n",
        "print()\n",
        "# tail by default 5 last rows of data deta    tail(n) or tail()\n",
        "print(df.tail())\n",
        "print()\n",
        "print(df.tail(7))\n",
        "print()\n",
        "\n",
        "\n",
        "\n",
        "print()\n",
        "# info()    -> numbers of row and columes , columes name , int64 float64 object , non null counts , memory usage of the data frame\n",
        "df.info()\n",
        "print()\n",
        "df['age'].info()\n",
        "\n",
        "\n",
        "print()\n",
        "# describe\n",
        "print(df.describe())\n",
        "print()\n",
        "\n",
        "print()\n",
        "# Condition to find min age person name df[condition][colname which info you want to get]\n",
        "print(df[df['age'] == 20.2]['fare'])\n",
        "\n",
        "# How big is your data set  -> shape\n",
        "print(df.shape)   # (rows , cols)\n",
        "print(df.shape[0])# row\n",
        "print(df.shape[1])# Colume\n",
        "\n",
        "# Colume name\n",
        "print(df.columns)\n",
        "\n",
        "data = {\n",
        "    'Std_id': [101, 101, 102, 102, 103],\n",
        "    'Name': ['Ali', 'Ali', 'Sara', 'Sara', 'Ahmed'],\n",
        "    'Math': [85, 85, 90, 90, 78],\n",
        "    'Physics': [88, 88, 92, 92, 80]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Original Data:\\n\", df)\n",
        "\n",
        "# Remove duplicates\n",
        "df_unique = df.drop_duplicates()\n",
        "print(\"\\nData After Removing Duplicates:\\n\", df_unique)\n",
        "\n",
        "print('Duplicates are : ',df.duplicated().sum())"
      ],
      "metadata": {
        "id": "VNQ3IzhBb0f9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering Data"
      ],
      "metadata": {
        "id": "cjlpuMfMdD9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('D:/Data Analyst/2_Pandas/5_Function/sample_data.csv')\n",
        "print(df)\n",
        "\n",
        "# Selecting Columes\n",
        "# 1- One colume ko select kiya tu series bane gi\n",
        "# 2- more than one colume ko select kiya tu data frame bane ga\n",
        "# syntax..\n",
        "# colume = df['col_name']     # for single colume\n",
        "print(df['Age'])\n",
        "# multi_colume = df[ 'col_name' , 'col_name2' , '.....' ]     # for single\n",
        "print(df[ ['Age','Name'] ])\n",
        "\n",
        "\n",
        "# Selecting or filtering Rows\n",
        "# filtered_row = df[ df['col_name'] < value ] # Single Condition\n",
        "print(df[df['Age'] > 23])\n",
        "print()\n",
        "# filtered_row = df[ (df['col_name'] < value) & (df['col_name'] < value)] # Multi Condition\n",
        "print(df[(df['Age'] > 23) & (df['Name'] == 'Usman')])\n",
        "print()\n",
        "print(df[(df['Age'] > 23) | (df['Name'] == 'Usman')])\n",
        "\n",
        "# between\n",
        "print(df[df['Age'].between(1, 22)])\n",
        "print(df['Age'].unique()) # only unique data deta\n",
        "print(df['Age'].nunique())# count() deta unique ka\n",
        "\n",
        "\n",
        "# Contain Function\n",
        "\n",
        "# df['column_name'].str.contains('keyword', case=True/False, na=False)\n",
        "\n",
        "# | Parameter    | Kaam                                                                   |\n",
        "# | ------------ | ---------------------------------------------------------------------- |\n",
        "# | `'keyword'`  | Jo word ya pattern aap dhundhna chahte ho                              |\n",
        "# | `case=False` | Case-insensitive search (e.g., `\"Documentaries\"` == `\"documentaries\"`) |\n",
        "# | `na=False`   | Agar value `NaN` ho to `False` return kare                             |\n",
        "\n",
        "\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'listed_in': [\n",
        "        'Documentaries, International Movies',\n",
        "        'Comedies, Action',\n",
        "        'Stand-Up Comedy',\n",
        "        'Documentaries'\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Find rows where 'Documentaries' is present\n",
        "# print(df['listed_in'].str.contains('documentaries', case=False))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('D:/Data Analyst/2_Pandas/5_Function/sample_data.csv')\n",
        "print(df)\n",
        "print()\n",
        "\n",
        "\n",
        "# Get colume\n",
        "print(df.columns)\n",
        "print()\n",
        "\n",
        "\n",
        "# Get data by slicing\n",
        "print(df[3:7])\n",
        "\n",
        "\n",
        "# Get index\n",
        "print(df.index)\n",
        "print()\n",
        "\n",
        "# Get index value in array\n",
        "print(df.index.array)\n",
        "print()\n",
        "\n",
        "\n",
        "# convert data into numpy\n",
        "print(df.to_numpy())\n",
        "print()\n",
        "\n",
        "# Descending Order of index\n",
        "print(df.sort_index(axis=0,ascending=False))   # axis = 0 means row\n",
        "print()\n",
        "# or\n",
        "print(df.sort_values(by=['Age'],ascending=False))   # ye colume ki value desending me change kerdeta hai\n",
        "print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Change Data in file\n",
        "df.loc[0,'Name'] = 'Khuzaima'\n",
        "print(df)\n",
        "print()\n",
        "\n",
        "# Particular Data\n",
        "print(df.loc[[2,3,4,5,6] , ['Name' , 'Age']])   # [row,col]\n",
        "print(df.loc[: , ['Name' , 'Age']])\n",
        "print(df.loc[[2,3,4,5,6] , : ])\n",
        "# 1. loc — Label-based indexing\n",
        "# Iska matlab: Aap rows aur columns ko unke labels (names) se select karte hain.\n",
        "# Row aur column ke actual index names ya column ke naam specify karne hote hain.\n",
        "# Inclusive hota hai, matlab agar aap slice kar rahe hain loc[1:3] to row labels 1 se 3 tak (including 3) sab aayenge.\n",
        "\n",
        "# or\n",
        "# By iloc\n",
        "# Particular Data\n",
        "print()\n",
        "print(df.iloc[0 , 2])\n",
        "# 2. iloc — Position-based indexing\n",
        "# Iska matlab: Aap rows aur columns ko unke integer position se select karte hain (0-based indexing).\n",
        "# Yahan labels nahi, sirf numbers use karte hain.\n",
        "# Slice mein upper bound exclusive hota hai (like standard Python slicing).\n",
        "\n",
        "\n",
        "\n",
        "# Drop Function\n",
        "df = df.drop('Email',axis=1) # Colume\n",
        "print(df)\n",
        "df = df.drop([2,3,4],axis=0) # Row\n",
        "print(df)\n",
        "\n",
        "# or\n",
        "df.drop(columns=['Age'] , axis=1 , inplace=True)\n",
        "print(df)\n",
        "# print(df.loc[[2,3,4,5,6] , ['Name' , 'Age']])   # [row,col]\n"
      ],
      "metadata": {
        "id": "Oas504khdV0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop & Fill null"
      ],
      "metadata": {
        "id": "HA7Xx7xHdhC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name' : ['Ali',None,'Sehzad','Akbar',None,'Javed','Saleem','Imran',None,'Iqbal'],\n",
        "    'Salary': [None,5000,1000,None,5000,8000,None,18000,None,40000],\n",
        "    'Bonus' : [8000,0,8000,None,8000,None,8000,80000,None,8000],\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "# Isnull   -> batahai true ager data nh hai and bata hai false ager data hai\n",
        "print(df.isnull())\n",
        "print()\n",
        "# isnull().sum() ye mujhe series provide karega each colume and bataega ke Kitne null hai in each colume\n",
        "print(df.isnull().sum())\n",
        "print()\n",
        "# print(df.describe()) koi issue nh aaega null data ki waja se\n",
        "\n",
        "# Dropna(axis = 0-1)\n",
        "print(df)\n",
        "print(df.dropna())  # Bydefault axis = 0 hota\n",
        "print(df.dropna(axis=1))  # data show nh karega bcz of null value in each colume\n",
        "print(df.dropna(how=\"all\")) # all mean if complete row null hai only unko remove\n",
        "print()\n",
        "\n",
        "# Fillna(any_value , axis = 0-1)\n",
        "print(df)\n",
        "print(df.fillna('\"\"\"No_data\"\"\"'))  # Bydefault axis = 0 hota  value(koi bhi datatype ki desakhte)\n",
        "print(df.fillna(0,axis=0))\n",
        "print(df.fillna({'Name':'NAAAAM', 'Salary' : 0.02 },axis=0))\n",
        "print() # Ab Ager Kisi Particular Colume me hi only value insert kerni ho tu\n",
        "\n",
        "df['Name'] = df['Name'].fillna('Onlyyyy')\n",
        "print(df)\n",
        "df['Salary'] = df['Salary'].fillna(df['Salary'].mean())\n",
        "print(df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {\n",
        "    'Name': ['Ali',   'Sara',   'Ahmed', 'Zara'],\n",
        "    'Age': [   25     , None    , 20    ,None],\n",
        "    'City': ['Lahore','Karachi', None, None]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "print()\n",
        "# Drop rows where 'Age' or 'City' has NaN\n",
        "df_cleaned = df.dropna(subset=['Age','City'])\n",
        "# sirf un rows ko delete karo jahan Age ya City me NaN ho.\n",
        "print(df_cleaned)\n",
        "\n",
        "# tresh\n",
        "df_cleaned = df.dropna(thresh=1)\n"
      ],
      "metadata": {
        "id": "m_Wvu28KdkXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace"
      ],
      "metadata": {
        "id": "9nBuSaeGgvMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.DataFrame({\n",
        "    'EmployeeID': [101, 102, 103, 104],\n",
        "    'Name': ['Ali', 'Sara', 'Ahmed', 'Zara'],\n",
        "    'Department': ['Sales', 'HR', 'IT', 'Marketing']\n",
        "})\n",
        "\n",
        "print(df1)\n",
        "print()\n",
        "\n",
        "# df.replace(to_replace = value , value = value)\n",
        "df1 = df1.replace(to_replace='Sara' , value='Tara')\n",
        "print(df1)\n",
        "df1.replace(inplace=True,to_replace=101 , value=100)\n",
        "print(df1)\n",
        "print()\n",
        "print(df1.replace(100,55))\n",
        "print(df1.replace('Sales',55))\n",
        "\n",
        "\n",
        "# https://www.youtube.com/watch?v=kQQaO5Cm5AI  for more replace function"
      ],
      "metadata": {
        "id": "-AOmzt_0dn3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `# **# #SEABORNS**`"
      ],
      "metadata": {
        "id": "T3JLhRArd1AV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scater **Plot**"
      ],
      "metadata": {
        "id": "2y0ZQ9ukeGKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df = sns.load_dataset('penguins')\n",
        "\n",
        "# Columns\n",
        "# ['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n",
        "#        'flipper_length_mm', 'body_mass_g', 'sex']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Plotting\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Hue -> basically category distinguish like male , female\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Style\n",
        "    # white\n",
        "    # dark\n",
        "    # whitegrid\n",
        "    # darkgrid\n",
        "    # ticks\n",
        "sns.set_style('dark')\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex')\n",
        "plt.show()\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex')\n",
        "plt.show()\n",
        "\n",
        "sns.set_style('darkgrid')\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex')\n",
        "plt.show()\n",
        "\n",
        "sns.set_style('ticks')\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex')\n",
        "plt.show()\n",
        "\n",
        "sns.set_style('white')\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# despine()  -> is used to remove outline of chart\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex')\n",
        "sns.despine()\n",
        "plt.show()\n",
        "\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex')\n",
        "sns.despine(bottom=True,left=True,right=False,top=False)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# set_context()\n",
        "#   poster\n",
        "#   Paper\n",
        "#   notebook\n",
        "#   talk\n",
        "\n",
        "sns.set_context('poster')\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex')\n",
        "plt.show()\n",
        "\n",
        "sns.set_context('paper')\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex')\n",
        "plt.show()\n",
        "\n",
        "sns.set_context('notebook')\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex')\n",
        "plt.show()\n",
        "\n",
        "sns.set_context('talk')\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Palette\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex',palette='Set1')\n",
        "plt.show()\n",
        "\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex',palette='Set2')\n",
        "plt.show()\n",
        "\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex',palette='Set3')\n",
        "plt.show()\n",
        "\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex',palette='deep')\n",
        "plt.show()\n",
        "\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex',palette='muted')\n",
        "plt.show()\n",
        "\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex',palette='bright')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Style()\n",
        "sns.set_context('paper')\n",
        "sns.scatterplot(data=df , x = 'species' , y = 'body_mass_g' , hue='island',style='sex')\n",
        "plt.show()\n",
        "\n",
        "sns.scatterplot(data=df , x = 'species' , y = 'body_mass_g' , hue='sex',style='island')\n",
        "plt.show()\n",
        "\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex',style='species')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Alpha\n",
        "sns.scatterplot(data = df , x = 'flipper_length_mm' , y = 'body_mass_g', hue='sex',style='species',alpha = 0.5)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "#               !!! In order to More clarity view we go to strip plot"
      ],
      "metadata": {
        "id": "WNLgSHM9d5s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Box Plot"
      ],
      "metadata": {
        "id": "HJ3l_ObgeJz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Columns Names\n",
        "# ['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n",
        "#        'flipper_length_mm', 'body_mass_g', 'sex']\n",
        "\n",
        "\n",
        "df = sns.load_dataset('penguins')\n",
        "\n",
        "\n",
        "# box plot\n",
        "sns.set_style('darkgrid')\n",
        "sns.boxplot(data = df, x= \"species\", y = \"body_mass_g\")\n",
        "plt.show()\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "sns.boxplot(data = df, x= \"species\", y = \"body_mass_g\", hue = \"island\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MPNGZhfRd8df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar Plot"
      ],
      "metadata": {
        "id": "tIjFCDI6eOnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Columns Names\n",
        "# ['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n",
        "#        'flipper_length_mm', 'body_mass_g', 'sex']\n",
        "\n",
        "\n",
        "df = sns.load_dataset('penguins')\n",
        "\n",
        "# Bar Plot\n",
        "# print(df[df[\"species\"] == 'Adelie'][\"body_mass_g\"].mean())\n",
        "sns.barplot(data = df, x =\"species\", y = \"body_mass_g\")\n",
        "plt.show()\n",
        "\n",
        "sns.barplot(data = df, x =\"species\", y = \"body_mass_g\" , hue='island')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "sns.barplot(data = df, x = \"species\", y= \"body_mass_g\", hue= \"sex\", palette = [\"pink\", \"blue\"])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Estimator = np.func_name  -> for performing operation on y axis value\n",
        "sns.barplot(data = df, x = \"species\", y= \"body_mass_g\", hue= \"sex\", palette = [\"pink\", \"blue\"], estimator=np.sum)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "sns.barplot(data = df, x= \"body_mass_g\", y = \"flipper_length_mm\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jPTd1VBheP-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histogram"
      ],
      "metadata": {
        "id": "4SjrxZ2feQ8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df = sns.load_dataset('penguins')\n",
        "\n",
        "# Columns\n",
        "# ['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n",
        "#        'flipper_length_mm', 'body_mass_g', 'sex']\n",
        "\n",
        "\n",
        "# hist plot  -> use for frequency\n",
        "sns.histplot(data = df , y = 'body_mass_g')\n",
        "plt.show()\n",
        "\n",
        "sns.histplot(data = df ,bins=15, x = 'body_mass_g' ,hue = 'island')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# multiple -> use for clarify the bars on graph\n",
        "#   'layer', 'dodge', 'stack', 'fill'\n",
        "sns.histplot(data = df , x = 'body_mass_g' ,hue = 'island' , multiple = 'layer')\n",
        "plt.show()\n",
        "\n",
        "sns.histplot(data = df , x = 'body_mass_g' ,hue = 'island' , multiple = 'dodge')\n",
        "plt.show()\n",
        "\n",
        "sns.histplot(data = df , x = 'body_mass_g' ,hue = 'island' , multiple = 'stack')\n",
        "plt.show()\n",
        "\n",
        "sns.histplot(data = df , x = 'body_mass_g' ,hue = 'island' , multiple = 'fill')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yQcvKSd1eVA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Plot"
      ],
      "metadata": {
        "id": "nt4vO6LqeV29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Columns Names\n",
        "# ['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n",
        "#        'flipper_length_mm', 'body_mass_g', 'sex']\n",
        "\n",
        "\n",
        "df = sns.load_dataset('penguins')\n",
        "\n",
        "\n",
        "# Count Plot  -> Row Count\n",
        "# print(df[df[\"species\"] == 'Gentoo'][\"body_mass_g\"].shape)\n",
        "sns.countplot (data = df, x = \"species\", hue='sex')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kDSa7TZcecaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heat Map"
      ],
      "metadata": {
        "id": "JTwaTkcpefBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Columns Names\n",
        "# ['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n",
        "#        'flipper_length_mm', 'body_mass_g', 'sex']\n",
        "\n",
        "\n",
        "\n",
        "df = sns.load_dataset('penguins')\n",
        "\n",
        "\n",
        "\n",
        "# Heatmap: a 20 color-coded matrix that shows relationships or patterns between two variables.\n",
        "# It's commonly used to:\n",
        "# - Show correlation between features\n",
        "# Visualize confusion matrices -> will see in the later stages.\n",
        "# Highlight missing data -> sns.heatmap(df.isnull())\n",
        "# ye banata hai grph to show co-relation between numerical colume\n",
        "\n",
        "numerical_columes = ['bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g']\n",
        "print(df[numerical_columes].corr())\n",
        "\n",
        "sns.heatmap(data=df[numerical_columes].corr())\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "#                                   Parameters,,,,,........\n",
        "\n",
        "\n",
        "# Min Max Value on color_bar\n",
        "sns.heatmap(data=df[numerical_columes].corr(), vmin=-5 , vmax=15)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Cmap\n",
        "sns.heatmap(data=df[numerical_columes].corr(), cmap='BuGn')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Annot\n",
        "sns.heatmap(data=df[numerical_columes].corr(),annot=True)  # Annot true se color number bhi block per show hoga\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Custom Annot array (same shape)\n",
        "data = np.array([[80, 90],\n",
        "                 [70, 60]])\n",
        "labels = np.array([['B', 'A'],\n",
        "                   ['C', 'D']])\n",
        "sns.heatmap(data, annot=labels, fmt='s', cmap='YlOrRd')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Annot Properties Changes\n",
        "x = {\n",
        "    'color' : 'white',\n",
        "    'fontsize' : 20\n",
        "}\n",
        "sns.heatmap(data=df[numerical_columes].corr(),annot=True , annot_kws=x)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Line Color\n",
        "sns.heatmap(data=df[numerical_columes].corr(),annot=True ,linewidths=1,linecolor='green')\n",
        "plt.show()\n",
        "\n",
        "# Remove Color Bar\n",
        "sns.heatmap(data=df[numerical_columes].corr(),annot=True , cbar=False )\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Remove xticks,yticks labels\n",
        "sns.heatmap(data=df[numerical_columes].corr(),annot=True ,xticklabels=False , yticklabels=False)\n",
        "plt.xlabel(\"X_Axis\")\n",
        "plt.ylabel(\"Y_Axis\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8UrJC9e_egFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pair Plot"
      ],
      "metadata": {
        "id": "EdfkwuNHeigd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Columns Names\n",
        "# ['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n",
        "#        'flipper_length_mm', 'body_mass_g', 'sex']\n",
        "\n",
        "\n",
        "df = sns.load_dataset('penguins')\n",
        "\n",
        "\n",
        "# Pair Plot  #by default sirf numerical columns hi pick karta hai — aapko manually specify karne ki zarurat nahi hoti (unless aap chaho).\n",
        "sns.pairplot(data = df)\n",
        "plt.show()\n",
        "\n",
        "sns.pairplot(data = df)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# diag_kind = 'auto' , 'hist' ,'kde'\n",
        "sns.pairplot(data = df, hue=\"sex\", palette=\"Set2\",diag_kind='kde')\n",
        "plt.show()\n",
        "# or\n",
        "sns.pairplot(data = df, hue=\"sex\", palette=\"Set2\",diag_kind='auto')\n",
        "plt.show()\n",
        "# or\n",
        "sns.pairplot(data = df, hue=\"sex\", palette=\"Set2\",diag_kind='hist')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "sns.pairplot(data = df)\n",
        "plt.show()\n",
        "# pair grid subpiot grid for plotting pairwise relationships in dataset.\n",
        "graph =  sns.PairGrid(data = df, hue = \"sex\", palette = \"Set2\")\n",
        "graph.map_upper(sns.scatterplot)\n",
        "graph.map_lower(sns.kdeplot)\n",
        "graph.map_diag(sns.histplot)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yGP7FsmmejXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `### # #DATA CLEANING`"
      ],
      "metadata": {
        "id": "DKSP_8itetgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null"
      ],
      "metadata": {
        "id": "7KgCUT56fTvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv('D:/Data Analyst/0_Data_Cleaning/googleplaystore.csv')\n",
        "# print(df.head())\n",
        "\n",
        "print(df.isnull().sum())\n",
        "print(df.shape)\n",
        "\n",
        "# Percentage for null value\n",
        "percentage = df.isnull().sum()/df.shape[0]*100\n",
        "print('Null value percentage in each colume',percentage)\n",
        "\n",
        "# Total Null Values in each colume ka sum\n",
        "totalnull = df.isnull().sum().sum()\n",
        "print('Total Null Values in dataset',totalnull)\n",
        "\n",
        "# Total dataset me null value ka percentage\n",
        "nullpercentage = df.isnull().sum().sum() / (df.shape[0] * df.shape[1]) * 100\n",
        "print('Total Null Values Percentage in dataset',nullpercentage)\n",
        "\n",
        "\n",
        "\n",
        "# Not Null Values in dataset\n",
        "notnull = df.notnull().sum()\n",
        "print(notnull)\n",
        "\n",
        "# Not Null Values in dataset\n",
        "totalnotnull = df.notnull().sum().sum()\n",
        "print(totalnotnull)\n",
        "\n",
        "# Not Null Values in dataset\n",
        "totalnotnullpercentage = df.notnull().sum().sum()/ (df.shape[0] * df.shape[1]) * 100\n",
        "print(totalnotnullpercentage)\n",
        "\n",
        "# Show nulls on graph\n",
        "sns.heatmap(df.isnull())\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Check Null\n",
        "# Check column nulls\n",
        "# Check percentage of null\n",
        "# graph of nulls"
      ],
      "metadata": {
        "id": "imN2wl1pewxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop Missing Value"
      ],
      "metadata": {
        "id": "KnOxgxDofVgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv('D:/Data Analyst/0_Data_Cleaning/googleplaystore.csv')\n",
        "# print(df.head())\n",
        "\n",
        "print(df.isnull().sum())\n",
        "print(df.shape)\n",
        "totalrows = df.shape[0]\n",
        "totalcolume = df.shape[1]\n",
        "\n",
        "# Drop nulls\n",
        "df.dropna(inplace=True)\n",
        "nowtotalrows = df.shape[0]  # After deleting Nulls\n",
        "nowtotalcolume = df.shape[1] # After deleting Nulls\n",
        "\n",
        "print('Show Deleting date in Percentage After Deleting Nulls')\n",
        "TotalDataBefore_nullsDelete = totalrows * totalcolume\n",
        "TotalDataAfter_nullsDelete = nowtotalrows * nowtotalcolume\n",
        "print(TotalDataBefore_nullsDelete)\n",
        "print(TotalDataAfter_nullsDelete)\n",
        "\n",
        "\n",
        "# Non Nulls Data\n",
        "print(TotalDataAfter_nullsDelete/TotalDataBefore_nullsDelete*100)  # Ye Non Null Percentage hai data ki\n",
        "# or\n",
        "print(nowtotalrows/totalrows*100)\n",
        "\n",
        "\n",
        "# Data After Deleted Nulls Data\n",
        "print((TotalDataBefore_nullsDelete - TotalDataAfter_nullsDelete)/(TotalDataBefore_nullsDelete)*100)\n",
        "# or\n",
        "print((totalrows-nowtotalrows)/(totalrows)*100)"
      ],
      "metadata": {
        "id": "9ontJLrufYoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill Missing Value"
      ],
      "metadata": {
        "id": "Tmn1JIBNfffd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "\n",
        "data = {\n",
        "    \"Name\": [\"Ali\",'Yumna', \"Sara\", np.nan, \"Fatima\", \"Hassan\", np.nan, \"Ayesha\"],   # object with NaN\n",
        "    \"Subject\": [\"IT\",'AI', np.nan, \"Finance\", \"IT\", \"HR\", np.nan, \"Finance\"],   # object with NaN\n",
        "    \"Age\": [23,23, np.nan, 30, np.nan, 28, 26, np.nan],                         # int with NaN\n",
        "    \"Salary\": [50000.0,10000.5, 60000.5, np.nan, 48000.0, np.nan, np.nan, 70000.0],  # float with NaN\n",
        "    \"Department\": [\"IT\",'AI', np.nan, \"Finance\", \"IT\", \"HR\", np.nan, \"Finance\"]   # object with NaN\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "si = SimpleImputer(strategy = 'mean')\n",
        "si.fit(df[['Age','Salary']]) #SimpleImputer Series ke saath direct kaam nahi karta, usko 2D array ya DataFrame chahiye hota hai.\n",
        "# SimpleImputer ka transform usi shape / features ke liye kaam karta hai jinke upar fit kiya gaya tha.\n",
        "\n",
        "Numeric_df = pd.DataFrame(si.transform(df[['Age','Salary']]),columns = ['Age','Salary'])\n",
        "print(Numeric_df)\n",
        "\n",
        "\n",
        "# Object Columns\n",
        "si = SimpleImputer(strategy='most_frequent')\n",
        "si.fit(df[['Name','Subject','Department']])\n",
        "Object_df = pd.DataFrame(si.transform(df[['Name','Subject','Department']]),columns = [['Name','Subject','Department']])\n",
        "print(Object_df)"
      ],
      "metadata": {
        "id": "1k6Yw2Y5fgvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `**# # LABEL ENCODER**`"
      ],
      "metadata": {
        "id": "xo8RQBvlfmFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "data = {\n",
        "    \"Name\": [\"Ali\",'Yumna', \"Sara\",  \"Fatima\", \"Hassan\", \"Ayesha\"],   # object\n",
        "    \"Age\": [23,23, 30,  28, 26, 50],                         # int\n",
        "    \"Salary\": [50000.0,10000.5, 60000.5,  48000.0, 30000.1, 70000.0],  # float\n",
        "    \"Department\": [\"IT\",'AI', \"Finance\", \"IT\", \"HR\", \"Finance\"]  # object\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "#                                   For Nominal Data\n",
        "le = LabelEncoder()\n",
        "# Label Encoding ek technique hai jisme categorical data (strings ya labels) ko numeric form me convert kiya jata hai,\n",
        "# taki machine learning algorithms easily use kar saken.\n",
        "# LabelEncoder sirf 1D array / Series accept karta hai.\n",
        "\n",
        "le.fit(df['Name'])\n",
        "df['Name_LE'] = le.transform(df['Name'])\n",
        "print(df[['Name','Name_LE']])\n"
      ],
      "metadata": {
        "id": "2NzW46Olfpn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `**# #ONE HOT ENCODING**`"
      ],
      "metadata": {
        "id": "Qep0kGhcfrV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = {\n",
        "    \"Name\": [\"Ali\",'Yumna', \"Sara\",  \"Fatima\", \"Hassan\", \"Ayesha\"],   # object\n",
        "    \"Subject\": [\"IT\",'AI', \"Finance\", \"IT\", \"HR\", \"Finance\"],   # object\n",
        "    \"Age\": [23,23, 30,  28, 26, 50],                         # int\n",
        "    \"Salary\": [50000.0,10000.5, 60000.5,  48000.0, 30000.1, 70000.0],  # float\n",
        "    \"Department\": [\"IT\",'AI', \"Finance\", \"IT\", \"HR\", \"Finance\"],   # object\n",
        "    \"Decision\": [\"Yess\",'No', \"No\", \"Yess\", \"Yess\", \"No\"], #object\n",
        "    \"Gender\": [\"Male\",'Female', \"Female\", \"Male\", \"Male\", \"Female\"] #object\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# One Hot Encoding Tab kerte haija colume me Category data present hu in object colume\n",
        "\n",
        "# Ab jab aesa data hu jis me col_object colume me Category data present hu\n",
        "#  Two ways hai jinse category colume ko convert kiya ja sakta hai from object type to other type\n",
        "# 1) from Pandas\n",
        "# 2) from sk-learn\n",
        "\n",
        "# isme data me jitni category hongi unme break hota chala jae ga alag column me\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#                                        1) From Pandas\n",
        "col = df[['Decision','Gender']]\n",
        "col.info()  # ye boolean me convert kerta hai by default aap dtype se type change kersakhte hu\n",
        "print()\n",
        "col = pd.get_dummies(col , dtype=int)\n",
        "col.info()\n",
        "print(col)\n",
        "# Jaha data present waha 1 jaha data present nahi waha 0\n",
        "\n",
        "\n",
        "\n",
        "#                                        2) From Sk-Learn\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ohe = OneHotEncoder()\n",
        "ohe.fit(df[['Decision','Gender']])\n",
        "\n",
        "print(ohe.transform(df[['Decision','Gender']]))\n",
        "# <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
        "        # with 12 stored elements and shape (6, 4)>\n",
        "\n",
        "# sparse matrix me data zyada tar 0 and 1 me hota hai\n",
        "\n",
        "\n",
        "ohe_df = ohe.transform(df[['Decision','Gender']]).toarray()\n",
        "ohe_df = pd.DataFrame(ohe_df,columns=['Decision_No','Decision_Yess','Gender_Female', 'Gender_Male'])\n",
        "print(ohe_df)\n",
        "\n",
        "# print(ohe.categories_)  #Colname jaane ke liye\n",
        "\n",
        "# or\n",
        "\n",
        "# colnames = []\n",
        "# for i, cat_list in enumerate(ohe.categories_):\n",
        "#     colnames.extend([f\"{df.columns[i]}_{val}\" for val in cat_list])\n",
        "# print(colnames)\n"
      ],
      "metadata": {
        "id": "wG0kUV_Pfx2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `**# # ORDINAL ENCODING**`"
      ],
      "metadata": {
        "id": "57OZUhdkf4F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "\n",
        "\n",
        "data = {\n",
        "    \"Sizes\": ['s','m','l','m','xl','xxl'],\n",
        "    \"Position_Holder\": [\"IT\",'AI', \"Finance\", \"IT\", \"HR\", \"Finance\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "#                   For Ordinal Data\n",
        "# 2) Methods for Labeling\n",
        "\n",
        "\n",
        "print(df['Sizes'].unique())\n",
        "# 1)                    SK-Learn\n",
        "# oe = OrdinalEncoder(categories=[df['Sizes'].unique()])   # [0,1,2,3]\n",
        "# or\n",
        "oe = OrdinalEncoder(categories=[['s','m','l','xl','xxl']])   # [0,1,2,3]\n",
        "oe.fit(df[['Sizes']])\n",
        "print(oe.transform(df[['Sizes']]))\n",
        "df['Sizes_Encoding'] = oe.transform(df[['Sizes']])\n",
        "print(df)\n",
        "\n",
        "\n",
        "# 2)                    Pandas  Not for huge data\n",
        "df['Sizes_Encoding_2'] = df['Sizes'].map(\n",
        "                                         {'s' : 1,'m' : 2,'l' : 3,'xl' :6 ,'xxl':7}\n",
        "                                         )\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "AisCDcScf8Z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `**# # OUTLIER REMOVAL**`"
      ],
      "metadata": {
        "id": "EI-4FGd6gKou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "data = {\n",
        "    \"Age\": [1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,100],\n",
        "    \"Salary\": [10,20,30,40,50,60,70,80,90,10,20,30,40,50,60,70,80,90,1000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# First humne Outlier ko dekhna hai\n",
        "sns.boxplot(data=df)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 3 Methods.....\n",
        "\n",
        "# 1) IQR (inter quartile range)\n",
        "\n",
        "# Ager Mene Age Ke Outliers Ko Remove kerna hai\n",
        "sns.boxplot(x = 'Age' ,data=df)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "q1 = df['Age'].quantile(0.25)\n",
        "q3 = df['Age'].quantile(0.75)\n",
        "print(q1,q3)\n",
        "iqr = q3-q1\n",
        "\n",
        "min_range = q1 - (1.5*iqr)\n",
        "max_range = q3 + (1.5*iqr)\n",
        "\n",
        "print(iqr,min_range,max_range)\n",
        "\n",
        "# Now i Print data in which no outlier present in my data\n",
        "df = df[(df['Age'] >= min_range) & (df['Age'] <= max_range)]\n",
        "print(df)\n",
        "sns.boxplot(x = 'Age' ,data=df)   # Outlier Remove Data\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "agutU8dmgOpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `**# #FEATURE SCALING**`"
      ],
      "metadata": {
        "id": "qT158osSgSal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardiztion"
      ],
      "metadata": {
        "id": "nY05LqyEgYRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "data = {\n",
        "    \"Age\": [1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,100],\n",
        "    \"Salary\": [10,20,30,40,50,60,70,80,90,10,20,30,40,50,60,70,80,90,1000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "ss = StandardScaler()\n",
        "ss.fit(df[['Age']])\n",
        "print(ss.transform(df[['Age']]))\n",
        "\n",
        "print(df.describe())\n",
        "df['Age_ss'] = pd.DataFrame(ss.transform(df[['Age']]) , columns=['Age'])\n",
        "print(df)\n",
        "print(df.describe())\n",
        "\n",
        "\n",
        "sns.histplot(df['Age'], kde=True, bins=30)\n",
        "plt.show()\n",
        "sns.histplot(df['Age_ss'] , kde = True)   # Scale Data\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ye manual formula hai\n",
        "df['Age_ss_2'] = (df['Age'] - df['Age'].mean())  / df['Age'].std(ddof=0)\n",
        "# ddof = Delta Degrees of Freedom.\n",
        "# Ye basically decide karta hai ke variance aur standard deviation calculate karte waqt denominator me n aayega ya n-1.\n",
        "\n",
        "\n",
        "\n",
        "print(df[['Age_ss','Age_ss_2']])\n",
        "print(df['Age'].std(ddof=0))\n",
        "print(df['Age'].std(ddof=1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# mean 0 and variance 1"
      ],
      "metadata": {
        "id": "0TNw3OIPgV_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization"
      ],
      "metadata": {
        "id": "TXPFARYqgbq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "data = {\n",
        "    \"Age\": [1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,100],\n",
        "    \"Salary\": [10,20,30,40,50,60,70,80,90,10,20,30,40,50,60,70,80,90,1000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "ss = MinMaxScaler()\n",
        "ss.fit(df[['Age']])\n",
        "print(ss.transform(df[['Age']]))\n",
        "\n",
        "print(df.describe())\n",
        "df['Age_ss'] = pd.DataFrame(ss.transform(df[['Age']]) , columns=['Age'])\n",
        "print(df)\n",
        "print(df.describe())\n",
        "\n",
        "\n",
        "sns.histplot(df['Age'], kde=True, bins=30)\n",
        "plt.show()\n",
        "sns.histplot(df['Age_ss'] , kde = True)   # Outlier Remove Data\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ye manual formula hai\n",
        "df['Age_ss_2'] = (df['Age'] - df['Age'].min())  / (df['Age'].max() - df['Age'].min())\n",
        "\n",
        "\n",
        "\n",
        "print(df[['Age_ss','Age_ss_2']])\n",
        "\n",
        "\n",
        "\n",
        "# # min is 0 max is 1"
      ],
      "metadata": {
        "id": "eoToaRdggdgs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`MODEL`**# **`MODEL`**# **`MODEL`**# **`MODEL`**"
      ],
      "metadata": {
        "id": "WRVw9n3khJpt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *# # LINEAR REGRESSION*"
      ],
      "metadata": {
        "id": "8nXTZY1EgfWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = final_df.drop('charges', axis=1)\n",
        "y = final_df['charges']  # Target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "model = LinearRegression()\n",
        "model.fit(X_train,y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "r2\n",
        "n = X_test.shape[0]\n",
        "p = X_test.shape[1]\n",
        "adjusted_r2 = 1 - ((1- r2) * (n-1) / (n - p - 1))\n",
        "adjusted_r2"
      ],
      "metadata": {
        "id": "pTtflqjqhCg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *# # LOGISTIC REGRESSION*"
      ],
      "metadata": {
        "id": "DY1HEl7ti741"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "\n",
        "model.fit(X_train,y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "y_test\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix , classification_report\n",
        "accuracy_score(y_test,y_pred)\n",
        "confusion_matrix(y_test,y_pred)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "tiiwwmZJi7et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *# # DECISION TREE CLASSIFICATION*"
      ],
      "metadata": {
        "id": "s-O_7RqWjhpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model_DT = DecisionTreeClassifier(random_state=42)\n",
        "model_DT.fit(X_train_scaled,y_train)\n",
        "y_pred_DT = model_DT.predict(X_test_scaled)\n",
        "y_pred_DT\n",
        "accuracy_score(y_test,y_pred_DT)\n",
        "confusion_matrix(y_test,y_pred_DT)\n",
        "print(classification_report(y_test,y_pred_DT))"
      ],
      "metadata": {
        "id": "dQpHUPQ8irnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *# # RANDOM FOREST TREE CLASSIFICATION*"
      ],
      "metadata": {
        "id": "3oGzy19hnx0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = final_df.drop('charges', axis=1)\n",
        "y = final_df['charges']  # Target\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators=20)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "model.score(X_test, y_test)\n",
        "\n",
        "y_predicted = model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_predicted)\n",
        "cm\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "plt.figure(figsize=(10,7))\n",
        "sn.heatmap(cm, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ],
      "metadata": {
        "id": "8jEuoSYWn2d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *# # SVM CLASSIFICATION*"
      ],
      "metadata": {
        "id": "NA_WnY8ikFnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "from sklearn.svm import SVC\n",
        "model_svm = SVC(kernel = 'linear')\n",
        "model_svm.fit(X_train_scaled, y_train)\n",
        "y_pred_svc = model_svm.predict(X_test_scaled)\n",
        "accuracy_score(y_test,y_pred_svc)\n",
        "confusion_matrix(y_test,y_pred_svc)\n",
        "print(classification_report(y_test,y_pred_svc))"
      ],
      "metadata": {
        "id": "WcTBb1SykHO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now Lets see what cross validation can do\n",
        "df\n",
        "X = df.drop('survived',axis = 1)\n",
        "y = df['survived']\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "scores = cross_val_score(model_svm,X_scaled,y,cv = 5,scoring= 'accuracy')\n",
        "print(scores)\n",
        "print(scores.mean())"
      ],
      "metadata": {
        "id": "JAUTMew8kfW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *# # KNN CLASSIFICATION*"
      ],
      "metadata": {
        "id": "y315akA3ksmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_model = KNeighborsClassifier(n_neighbors= 5)\n",
        "knn_model.fit(X_train_scaled,y_train)\n",
        "y_pred_knn = knn_model.predict(X_test_scaled)\n",
        "accuracy_score(y_test,y_pred_knn)\n",
        "confusion_matrix(y_test,y_pred_knn)\n",
        "print(classification_report(y_test,y_pred_knn))"
      ],
      "metadata": {
        "id": "QWgMnaDbkvfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *# # NAVED BIASES CLASSIFICATION*"
      ],
      "metadata": {
        "id": "lJDcHBNGlBbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "model_NB = GaussianNB()\n",
        "model_NB.fit(X_train,y_train)\n",
        "y_pred_NB = model_NB.predict(X_test)\n",
        "y_pred_NB\n",
        "accuracy_score(y_test,y_pred_NB)\n",
        "confusion_matrix(y_test,y_pred_NB)\n",
        "print(classification_report(y_test,y_pred_NB))"
      ],
      "metadata": {
        "id": "A0iQ5_xmlFcr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *# # `PEARSON CORRELATION`*"
      ],
      "metadata": {
        "id": "gCyHnX3Smk2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Extraction\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# --------------------------\n",
        "# # Pearson Correlation Calculation\n",
        "# --------------------------\n",
        "\n",
        "# List of features to check against target\n",
        "selected_features = [\n",
        "    'age', 'bmi', 'children', 'is_male', 'is_smoker',\n",
        "    'northeast', 'northwest', 'southeast','southwest',\n",
        "    'Normal', 'Overweights', 'Obese','Underweight'\n",
        "]\n",
        "correlations = {\n",
        "    feature: pearsonr(df_cleaned[feature], df_cleaned['charges'])[0]\n",
        "    for feature in selected_features\n",
        "}\n",
        "\n",
        "# for feature in selected_features\n",
        "# Ye loop har column (feature) ke liye chalega jo selected_features list me hai.\n",
        "# Example: 'age', 'bmi', 'children', 'is_smoker', etc.\n",
        "# pearsonr(df_cleaned[feature], df_cleaned['charges'])\n",
        "# Ye scipy.stats.pearsonr() function dono columns ke beech Pearson correlation calculate karta hai.\n",
        "# Ye 2 values return karta hai:\n",
        "# [0] → correlation coefficient (actual value)\n",
        "# [1] → p-value (statistical significance)\n",
        "# Tumhe sirf correlation chahiye, isliye [0] likha hai.\n",
        "# feature: ...\n",
        "# Ye dictionary ka key banega.\n",
        "# Value hogi us feature ka correlation with 'charges'.\n",
        "\n",
        "correlation_df = pd.DataFrame(list(correlations.items()), columns=['Feature', 'Pearson Correlation'])\n",
        "correlation_df.sort_values(by=['Pearson Correlation'] , ascending=False , inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# OR\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(df.corr(numeric_only=True), annot = True)"
      ],
      "metadata": {
        "id": "VTbfOn35mlP9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}